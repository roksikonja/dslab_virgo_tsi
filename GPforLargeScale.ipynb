{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import time\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from gpflow.ci_utils import ci_niter\n",
    "plt.style.use('ggplot')\n",
    "import time\n",
    "from gpflow.utilities import print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/2019-11-16_12-35-14_smooth_monotonic/smooth_monotonic_modeling_result.pkl', 'rb') as handle:\n",
    "    x = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_subsample = x.final.b_nn_corrected[::30][500:]\n",
    "time_subsample = x.base_signals.t_b_nn[::30][500:]\n",
    "mean = np.mean(x_subsample)\n",
    "X, Y = time_subsample, x_subsample - mean\n",
    "X, Y = X[np.greater_equal(Y, -2)],  Y[np.greater_equal(Y, -2)]\n",
    "X, Y = X[np.less_equal(Y, 3)],  Y[np.less_equal(Y, 3)]\n",
    "X, Y = X.reshape(-1,1), Y.reshape(-1,1)\n",
    "\n",
    "N = np.size(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5, figsize=(16, 8))\n",
    "plt.ylim(-3, 3)\n",
    "plt.plot(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=150\n",
    "interval = (np.min(time_subsample), np.max(time_subsample))\n",
    "time_indicies=np.linspace(interval[0], interval[1], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, values):\n",
    "    indices = np.zeros(values.shape)\n",
    "    for index, value in enumerate(values):\n",
    "        indices[index] = np.abs(array - value).argmin()\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.size(find_nearest(X, time_indicies).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = find_nearest(X, time_indicies).astype(int)\n",
    "\n",
    "kernel = gpflow.kernels.Sum([gpflow.kernels.Matern32(),gpflow.kernels.White()])\n",
    "Z = X[indices].copy()  # Initialise inducing locations\n",
    "M = np.size(Z)\n",
    "m = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z, num_data=N)\n",
    "m.kernel.kernels[0].lengthscale.assign(427)\n",
    "print_summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = tf.function(autograph=False)(m.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "log_likelihood(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 100\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X, Y)) \\\n",
    "    .repeat() \\\n",
    "    .shuffle(N)\n",
    "\n",
    "train_it = iter(train_dataset.batch(minibatch_size))\n",
    "\n",
    "ground_truth = m.log_likelihood(X, Y).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "log_likelihood(*next(train_it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = [log_likelihood(*minibatch).numpy()\n",
    "         for minibatch in itertools.islice(train_it, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(evals, label='Minibatch estimations')\n",
    "plt.axvline(ground_truth, c='k', label='Ground truth')\n",
    "plt.axvline(np.mean(evals), c='g', ls='--', label='Minibatch mean')\n",
    "plt.legend()\n",
    "plt.title('Histogram of ELBO evaluations using minibatches')\n",
    "print(\"Discrepancy between ground truth and minibatch estimate:\",\n",
    "      ground_truth - np.mean(evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate objective for different minibatch sizes\n",
    "minibatch_proportions = np.logspace(-2, 0, 10)\n",
    "times = []\n",
    "objs = []\n",
    "for mbp in minibatch_proportions:\n",
    "    batchsize = int(N * mbp)\n",
    "    train_it = iter(train_dataset.batch(batchsize))\n",
    "    start_time = time.time()\n",
    "    objs.append([log_likelihood(*minibatch)\n",
    "                 for minibatch in itertools.islice(train_it, 20)])\n",
    "    times.append(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "ax1.plot(minibatch_proportions, times, 'x-')\n",
    "ax1.set_xlabel(\"Minibatch proportion\")\n",
    "ax1.set_ylabel(\"Time taken\")\n",
    "\n",
    "ax2.plot(minibatch_proportions, np.array(objs), 'kx')\n",
    "ax2.set_xlabel(\"Minibatch proportion\")\n",
    "ax2.set_ylabel(\"ELBO estimates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(title=''):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(title)\n",
    "    pX = np.linspace(0, 9000, 100)[:, None]  # Test locations\n",
    "    pY, pYv = m.predict_y(pX)  # Predict Y values at test locations\n",
    "    plt.plot(X, Y, 'x', label='Training points', alpha=0.2)\n",
    "    line, = plt.plot(pX, pY, lw=1.5, label='Mean of predictive posterior')\n",
    "    col = line.get_color()\n",
    "    plt.fill_between(pX[:, 0], (pY-2*pYv**0.5)[:, 0], (pY+2*pYv**0.5)[:, 0], \n",
    "                     color=col, alpha=0.6, lw=1.5)\n",
    "    Z = m.inducing_variable.Z.numpy()\n",
    "    print(Z.shape)\n",
    "    plt.plot(Z, np.zeros_like(Z), 'k|', mew=2, label='Inducing locations')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylim(-3, 3)\n",
    "\n",
    "plot(title=\"Predictions before training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 100\n",
    "\n",
    "# We turn of training for inducing point locations\n",
    "gpflow.utilities.set_trainable(m.inducing_variable, False)\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def optimization_step(optimizer, model: gpflow.models.SVGP, batch):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        objective = - model.elbo(*batch)\n",
    "        grads = tape.gradient(objective, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return objective\n",
    "\n",
    "def run_adam(model, iterations):\n",
    "    \"\"\"\n",
    "    Utility function running the Adam optimiser\n",
    "    \n",
    "    :param model: GPflow model\n",
    "    :param interations: number of iterations\n",
    "    \"\"\"\n",
    "    # Create an Adam Optimiser action\n",
    "    logf = []\n",
    "    train_it = iter(train_dataset.batch(minibatch_size))\n",
    "    adam = tf.optimizers.Adam()\n",
    "    for step in range(iterations):\n",
    "        if step % 1000 == 0:\n",
    "            print('We are on the step {}'.format(step))\n",
    "        elbo = - optimization_step(adam, model, next(train_it))\n",
    "        if step % 10 == 0:\n",
    "            logf.append(elbo.numpy())\n",
    "    return logf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "maxiter = ci_niter(8000)\n",
    "\n",
    "logf = run_adam(m, maxiter)\n",
    "plt.plot(np.arange(maxiter)[::10], logf)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('ELBO');\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\"Predictions after training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.utilities import print_summary, positive\n",
    "from gpflow.utilities.ops import square_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import time\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from gpflow.ci_utils import ci_niter\n",
    "plt.style.use('ggplot')\n",
    "import time\n",
    "import pickle\n",
    "from gpflow.utilities import print_summary\n",
    "\n",
    "with open('./results/2019-11-16_23-12-39_smooth_monotonic/smooth_monotonic_modeling_result.pkl', 'rb') as handle:\n",
    "    x = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1162) (1162,) (2, 801) (801,)\n"
     ]
    }
   ],
   "source": [
    "x_subsample_a = x.final.a_nn_corrected[::10000]\n",
    "time_subsample_a = x.base_signals.t_a_nn[::10000]\n",
    "\n",
    "x_subsample_b = x.final.b_nn_corrected[::30][500:]\n",
    "time_subsample_b = x.base_signals.t_b_nn[::30][500:]\n",
    "\n",
    "mean = np.mean(np.concatenate((x_subsample_a, x_subsample_b)))\n",
    "\n",
    "X_a, Y_a = time_subsample_a, x_subsample_a - mean\n",
    "X_a, Y_a = X_a[np.greater_equal(Y_a, -2)],  Y_a[np.greater_equal(Y_a, -2)]\n",
    "X_a, Y_a = X_a[np.less_equal(Y_a, 3)],  Y_a[np.less_equal(Y_a, 3)]\n",
    "X_a = np.stack((X_a, np.ones(X_a.shape)))\n",
    "\n",
    "X_b, Y_b = time_subsample_b, x_subsample_b - mean\n",
    "X_b, Y_b = X_b[np.greater_equal(Y_b, -2)],  Y_b[np.greater_equal(Y_b, -2)]\n",
    "X_b, Y_b = X_b[np.less_equal(Y_b, 3)],  Y_b[np.less_equal(Y_b, 3)]\n",
    "X_b = np.stack((X_b, np.zeros(X_b.shape)))\n",
    "\n",
    "print(X_a.shape, Y_a.shape, X_b.shape, Y_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963, 2) (1963, 1)\n",
      "(66, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.transpose(np.concatenate((X_a, X_b), axis=1)).reshape(-1, 2)\n",
    "Y = np.transpose(np.concatenate((Y_a, Y_b), axis=0)).reshape(-1, 1)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "N=np.size(Y)\n",
    "\n",
    "Z = X[::30,:].copy()  # Initialise inducing locations\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirgoMatern32Kernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self):\n",
    "        super().__init__(active_dims=[0])\n",
    "        self.variance = gpflow.Parameter(1.0, transform=positive())\n",
    "        self.lengthscale = gpflow.Parameter(1.0, transform=positive())\n",
    "        \n",
    "    def scaled_squared_euclid_dist(self, X, X2=None):\n",
    "        \"\"\"\n",
    "        Returns ||(X - X2ᵀ) / ℓ||² i.e. squared L2-norm.\n",
    "        \"\"\"\n",
    "        X_scaled = X / self.lengthscale\n",
    "        X2_scaled = X2 / self.lengthscale if X2 is not None else X2\n",
    "        return square_distance(X_scaled, X2_scaled)\n",
    "\n",
    "    def K(self, X, X2=None, presliced=False):\n",
    "        if not presliced:\n",
    "            X, X2 = self.slice(X, X2)\n",
    "        X = tf.reshape(X[:, 0], [-1, 1])\n",
    "        X2 = tf.reshape(X2[:, 0], [-1, 1])\n",
    "        r2 = self.scaled_squared_euclid_dist(X, X2)\n",
    "        k = self.K_r2(r2)\n",
    "        print(\"K\", k.shape)\n",
    "        return k\n",
    "\n",
    "    def K_diag(self, X, presliced=False):\n",
    "        k_diag = tf.fill((X[:,0].shape[:-1]), tf.squeeze(self.variance))\n",
    "        print(\"K_diag\", k_diag.shape)\n",
    "        return k_diag\n",
    "        \n",
    "    def K_r2(self, r):\n",
    "        sqrt3 = np.sqrt(3.)\n",
    "        return self.variance * (1. + sqrt3 * r) * tf.exp(-sqrt3 * r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                      class      transform       trainable    shape        dtype    value\n",
      "------------------------  ---------  --------------  -----------  -----------  -------  ---------------------------------\n",
      "SVGP.kernel.variance      Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.kernel.lengthscale   Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.likelihood.variance  Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.inducing_variable.Z  Parameter                  True         (66, 2)      float64  [[4.8026000e+01, 1.0000000e+00...\n",
      "SVGP.q_mu                 Parameter                  True         (66, 1)      float64  [[0....\n",
      "SVGP.q_sqrt               Parameter  FillTriangular  True         (1, 66, 66)  float64  [[[1., 0., 0....\n",
      "K (66, 66)\n",
      "K (66, 1963)\n",
      "K_diag ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=502, shape=(), dtype=float64, numpy=-3048.8445284734576>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = VirgoMatern32Kernel()\n",
    "m = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z, num_data=N)\n",
    "print_summary(m)\n",
    "log_likelihood = tf.function(autograph=False)(m.log_likelihood)\n",
    "log_likelihood(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                      class      transform       trainable    shape        dtype    value\n",
      "------------------------  ---------  --------------  -----------  -----------  -------  ----------------\n",
      "SVGP.kernel.variance      Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.kernel.lengthscale   Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.likelihood.variance  Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.inducing_variable.Z  Parameter                  True         (66, 1)      float64  [[48.026...\n",
      "SVGP.q_mu                 Parameter                  True         (66, 1)      float64  [[0....\n",
      "SVGP.q_sqrt               Parameter  FillTriangular  True         (1, 66, 66)  float64  [[[1., 0., 0....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=949, shape=(), dtype=float64, numpy=-3048.8445284734576>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = gpflow.kernels.Matern32()\n",
    "m = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z[:, 0].reshape(-1, 1), num_data=N)\n",
    "print_summary(m)\n",
    "log_likelihood = tf.function(autograph=False)(m.log_likelihood)\n",
    "log_likelihood(X[:, 0].reshape(-1, 1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirgoWhiteKernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self):\n",
    "        super().__init__(active_dims=[0])\n",
    "        self.variance_a = gpflow.Parameter(1.0, transform=positive())\n",
    "        self.variance_b = gpflow.Parameter(1.0, transform=positive())\n",
    "        \n",
    "    def K(self, X, X2=None, presliced=None):\n",
    "        if X2 is None:\n",
    "            d_a = tf.fill((X.shape[0], 1), tf.squeeze(self.variance_a))\n",
    "            d_b = tf.fill((X.shape[0], 1), tf.squeeze(self.variance_b))\n",
    "            \n",
    "            indices_a = tf.cast(tf.reshape(tf.equal(X[:,1], 1), [-1, 1]), dtype=tf.float64)\n",
    "            indices_b = tf.cast(tf.reshape(tf.equal(X[:,1], 0), [-1, 1]), dtype=tf.float64)\n",
    "            \n",
    "            return tf.linalg.diag(tf.multiply(d_a, indices_a) + tf.multiply(d_b, indices_b))\n",
    "        else:\n",
    "            print(\"zeros\")\n",
    "            shape = [X.shape[0], X2.shape[0]]\n",
    "            return tf.zeros(shape, dtype=X.dtype)\n",
    "\n",
    "    def K_diag(self, X, presliced=None):\n",
    "        return self.K(X, X2=None, presliced=presliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirgoWhiteKernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self):\n",
    "        super().__init__(active_dims=[0])\n",
    "        self.variance_a = gpflow.Parameter(1.0, transform=positive())\n",
    "        self.variance_b = gpflow.Parameter(1.0, transform=positive())\n",
    "        \n",
    "    def K(self, X, X2=None, presliced=None):\n",
    "        if X2 is None:\n",
    "            d_a = tf.fill((X.shape[0], ), tf.squeeze(self.variance_a))\n",
    "            d_b = tf.fill((X.shape[0], ), tf.squeeze(self.variance_a))\n",
    "            indices_a = tf.cast(tf.equal(X[:,1], 0), dtype=tf.float64)\n",
    "            indices_b = tf.cast(tf.equal(X[:,1], 1), dtype=tf.float64)\n",
    "#             return tf.multiply(tf.linalg.diag(d_a), tf.linalg.diag(indices_a)) + tf.multiply(tf.linalg.diag(d_b), tf.linalg.diag(indices_b))\n",
    "            return tf.linalg.diag(tf.multiply(d_a, indices_a) + tf.multiply(d_b, indices_b))\n",
    "        else:\n",
    "            shape = [X.shape[0], X2.shape[0]]\n",
    "            return tf.zeros(shape, dtype=X.dtype)\n",
    "\n",
    "    def K_diag(self, X, presliced=None):\n",
    "        d_a = tf.fill((X.shape[0], ), tf.squeeze(self.variance_a))\n",
    "        d_b = tf.fill((X.shape[0], ), tf.squeeze(self.variance_a))\n",
    "        indices_a = tf.cast(tf.equal(X[:,1], 0), dtype=tf.float64)\n",
    "        indices_b = tf.cast(tf.equal(X[:,1], 1), dtype=tf.float64)\n",
    "        return tf.multiply(d_a, indices_a) + tf.multiply(d_b, indices_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                      class      transform       trainable    shape        dtype    value\n",
      "------------------------  ---------  --------------  -----------  -----------  -------  ---------------------------------\n",
      "SVGP.kernel.variance_a    Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.kernel.variance_b    Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.likelihood.variance  Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.inducing_variable.Z  Parameter                  True         (66, 2)      float64  [[4.8026000e+01, 1.0000000e+00...\n",
      "SVGP.q_mu                 Parameter                  True         (66, 1)      float64  [[0....\n",
      "SVGP.q_sqrt               Parameter  FillTriangular  True         (1, 66, 66)  float64  [[[1., 0., 0....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2406, shape=(), dtype=float64, numpy=-3048.8445284734576>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = VirgoWhiteKernel()\n",
    "m = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z, num_data=N)\n",
    "print_summary(m)\n",
    "log_likelihood = tf.function(autograph=False)(m.log_likelihood)\n",
    "log_likelihood(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                      class      transform       trainable    shape        dtype    value\n",
      "------------------------  ---------  --------------  -----------  -----------  -------  ----------------\n",
      "SVGP.kernel.variance      Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.likelihood.variance  Parameter  Softplus        True         ()           float64  1.0\n",
      "SVGP.inducing_variable.Z  Parameter                  True         (66, 1)      float64  [[48.026...\n",
      "SVGP.q_mu                 Parameter                  True         (66, 1)      float64  [[0....\n",
      "SVGP.q_sqrt               Parameter  FillTriangular  True         (1, 66, 66)  float64  [[[1., 0., 0....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2750, shape=(), dtype=float64, numpy=-3048.8445284734576>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = gpflow.kernels.White()\n",
    "m = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z[:, 0].reshape(-1, 1), num_data=N)\n",
    "print_summary(m)\n",
    "log_likelihood = tf.function(autograph=False)(m.log_likelihood)\n",
    "log_likelihood(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
